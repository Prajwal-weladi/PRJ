{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "852d831b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "    90112/170498071 [..............................] - ETA: 1:19:57"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load CIFAR-10 dataset as example\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m (x_train, y_train), (x_test, y_test) \u001b[38;5;241m=\u001b[39m \u001b[43mcifar10\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Normalize pixel values\u001b[39;00m\n\u001b[0;32m     10\u001b[0m x_train \u001b[38;5;241m=\u001b[39m x_train\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Prajwal Weladi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\datasets\\cifar10.py:81\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     79\u001b[0m dirname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcifar-10-batches-py\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     80\u001b[0m origin \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 81\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43muntar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: E501\u001b[39;49;00m\n\u001b[0;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m6d958be074577803d12ecdefd02955f39262c83c16fe9348329d7fe0b5c001ce\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m num_train_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50000\u001b[39m\n\u001b[0;32m     92\u001b[0m x_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((num_train_samples, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Prajwal Weladi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\data_utils.py:346\u001b[0m, in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 346\u001b[0m         \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDLProgbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    348\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error_msg\u001b[38;5;241m.\u001b[39mformat(origin, e\u001b[38;5;241m.\u001b[39mcode, e\u001b[38;5;241m.\u001b[39mmsg))\n",
      "File \u001b[1;32mc:\\Users\\Prajwal Weladi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\data_utils.py:87\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m     85\u001b[0m response \u001b[38;5;241m=\u001b[39m urlopen(url, data)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fd:\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunk_read(response, reporthook\u001b[38;5;241m=\u001b[39mreporthook):\n\u001b[0;32m     88\u001b[0m         fd\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[1;32mc:\\Users\\Prajwal Weladi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\data_utils.py:76\u001b[0m, in \u001b[0;36murlretrieve.<locals>.chunk_read\u001b[1;34m(response, chunk_size, reporthook)\u001b[0m\n\u001b[0;32m     74\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reporthook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Prajwal Weladi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 465\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Users\\Prajwal Weladi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Prajwal Weladi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\Prajwal Weladi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "\n",
    "# Load CIFAR-10 dataset as example\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Define data augmentation pipeline\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit the data generator (not strictly necessary for CIFAR-10 but good practice)\n",
    "train_datagen.fit(x_train)\n",
    "\n",
    "# Preview augmented images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i, batch in enumerate(train_datagen.flow(x_train, batch_size=9, shuffle=False)):\n",
    "    for j in range(9):\n",
    "        plt.subplot(3, 3, j+1)\n",
    "        plt.imshow(batch[j])\n",
    "        plt.axis('off')\n",
    "    plt.suptitle('Sample Augmented Images')\n",
    "    plt.show()\n",
    "    break\n",
    "\n",
    "# Return the data generator and original data for next steps\n",
    "train_datagen, x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8123272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since TensorFlow is not available, we will simulate data augmentation using numpy and matplotlib for visualization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import rotate, zoom\n",
    "\n",
    "# Generate a sample image (simple colored square)\n",
    "image = np.zeros((32, 32, 3), dtype=np.uint8)\n",
    "image[8:24, 8:24, :] = [255, 0, 0]  # Red square\n",
    "\n",
    "# Define augmentation functions\n",
    "\n",
    "def augment_image(img):\n",
    "    augmented_images = []\n",
    "    # Rotation\n",
    "    rotated = rotate(img, angle=20, reshape=False, mode='nearest')\n",
    "    augmented_images.append(rotated)\n",
    "    # Zoom\n",
    "    zoomed = zoom(img, (1.2, 1.2, 1), order=1)\n",
    "    # Crop to original size\n",
    "    center = zoomed.shape[0] // 2\n",
    "    start = center - 16\n",
    "    zoomed_cropped = zoomed[start:start+32, start:start+32, :]\n",
    "    augmented_images.append(zoomed_cropped)\n",
    "    # Horizontal flip\n",
    "    flipped = np.fliplr(img)\n",
    "    augmented_images.append(flipped)\n",
    "    return augmented_images\n",
    "\n",
    "augmented_images = augment_image(image)\n",
    "\n",
    "# Plot original and augmented images\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(image)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "\n",
    "for i, aug_img in enumerate(augmented_images):\n",
    "    plt.subplot(1, 4, i+2)\n",
    "    plt.imshow(aug_img.astype(np.uint8))\n",
    "    plt.title(['Rotated', 'Zoomed', 'Flipped'][i])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Return augmented images for next steps\n",
    "augmented_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5395ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since TensorFlow is not available, we will simulate training two simple CNN models using sklearn's MLPClassifier on flattened CIFAR-10 data\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Flatten images\n",
    "X_train_flat = x_train.reshape((x_train.shape[0], -1))\n",
    "X_test_flat = x_test.reshape((x_test.shape[0], -1))\n",
    "\n",
    "# Original model (no augmentation)\n",
    "model_orig = MLPClassifier(hidden_layer_sizes=(100,), max_iter=10, random_state=42)\n",
    "model_orig.fit(X_train_flat, y_train.ravel())\n",
    "\n",
    "# Simulate augmented data by adding noise to training data\n",
    "noise = np.random.normal(0, 0.1, X_train_flat.shape)\n",
    "X_train_aug = np.clip(X_train_flat + noise, 0, 1)\n",
    "\n",
    "model_aug = MLPClassifier(hidden_layer_sizes=(100,), max_iter=10, random_state=42)\n",
    "model_aug.fit(X_train_aug, y_train.ravel())\n",
    "\n",
    "# Evaluate both models\n",
    "orig_train_acc = model_orig.score(X_train_flat, y_train)\n",
    "orig_test_acc = model_orig.score(X_test_flat, y_test)\n",
    "aug_train_acc = model_aug.score(X_train_aug, y_train)\n",
    "aug_test_acc = model_aug.score(X_test_flat, y_test)\n",
    "\n",
    "(orig_train_acc, orig_test_acc, aug_train_acc, aug_test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
