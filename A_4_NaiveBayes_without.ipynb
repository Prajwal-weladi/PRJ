{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed32b216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "ID\tActual\t\tPredicted\tStatus\n",
      "----------------------------------------\n",
      "1\tIris-versicolor\tIris-versicolor\tCorrect\n",
      "2\tIris-setosa    \tIris-setosa    \tCorrect\n",
      "3\tIris-virginica \tIris-virginica \tCorrect\n",
      "4\tIris-versicolor\tIris-versicolor\tCorrect\n",
      "5\tIris-setosa    \tIris-setosa    \tCorrect\n",
      "6\tIris-setosa    \tIris-setosa    \tCorrect\n",
      "7\tIris-virginica \tIris-virginica \tCorrect\n",
      "8\tIris-virginica \tIris-virginica \tCorrect\n",
      "9\tIris-versicolor\tIris-versicolor\tCorrect\n",
      "10\tIris-setosa    \tIris-setosa    \tCorrect\n",
      "11\tIris-versicolor\tIris-versicolor\tCorrect\n",
      "12\tIris-setosa    \tIris-setosa    \tCorrect\n",
      "13\tIris-setosa    \tIris-setosa    \tCorrect\n",
      "14\tIris-setosa    \tIris-setosa    \tCorrect\n",
      "15\tIris-versicolor\tIris-versicolor\tCorrect\n",
      "16\tIris-virginica \tIris-virginica \tCorrect\n",
      "17\tIris-virginica \tIris-virginica \tCorrect\n",
      "18\tIris-setosa    \tIris-setosa    \tCorrect\n",
      "19\tIris-virginica \tIris-virginica \tCorrect\n",
      "20\tIris-versicolor\tIris-versicolor\tCorrect\n",
      "21\tIris-versicolor\tIris-virginica \tWrong\n",
      "22\tIris-virginica \tIris-versicolor\tWrong\n",
      "23\tIris-setosa    \tIris-setosa    \tCorrect\n",
      "24\tIris-setosa    \tIris-setosa    \tCorrect\n",
      "25\tIris-versicolor\tIris-versicolor\tCorrect\n",
      "26\tIris-versicolor\tIris-versicolor\tCorrect\n",
      "27\tIris-versicolor\tIris-versicolor\tCorrect\n",
      "28\tIris-virginica \tIris-virginica \tCorrect\n",
      "29\tIris-versicolor\tIris-versicolor\tCorrect\n",
      "30\tIris-virginica \tIris-virginica \tCorrect\n",
      "\n",
      "Final Metrics:\n",
      "Correct Predictions: 28\n",
      "Wrong Predictions: 2\n",
      "Accuracy: 93.33%\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "import random\n",
    "\n",
    "def load_iris_data(filename):\n",
    "    \"\"\"Load Iris dataset, skipping headers and ID column\"\"\"\n",
    "    data = []\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Skip header\n",
    "        for row in reader:\n",
    "            if not row: continue\n",
    "            # Skip ID column (index 0), convert features to float\n",
    "            features = [float(x) for x in row[1:-1]]\n",
    "            label = row[-1]\n",
    "            data.append(features + [label])\n",
    "    return data\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.class_info = {}\n",
    "        self.class_priors = {}\n",
    "\n",
    "    def train(self, train_data):\n",
    "        # Separate data by class\n",
    "        class_dict = {}\n",
    "        for record in train_data:\n",
    "            features = record[:-1]\n",
    "            label = record[-1]\n",
    "            if label not in class_dict:\n",
    "                class_dict[label] = []\n",
    "            class_dict[label].append(features)\n",
    "        \n",
    "        # Calculate statistics for each class\n",
    "        for label, samples in class_dict.items():\n",
    "            # Calculate mean and stddev for each feature\n",
    "            feature_stats = []\n",
    "            for i in range(len(samples[0])):\n",
    "                feature_vals = [s[i] for s in samples]\n",
    "                mean = sum(feature_vals)/len(feature_vals)\n",
    "                variance = sum((x-mean)**2 for x in feature_vals)/(len(feature_vals)-1)\n",
    "                stddev = math.sqrt(variance)\n",
    "                feature_stats.append((mean, stddev))\n",
    "            \n",
    "            self.class_info[label] = feature_stats\n",
    "            self.class_priors[label] = len(samples)/len(train_data)\n",
    "\n",
    "    def _gaussian_pdf(self, x, mean, stddev):\n",
    "        \"\"\"Calculate Gaussian probability density\"\"\"\n",
    "        if stddev < 1e-9:  # Handle zero variance\n",
    "            return 1.0 if x == mean else 0.0\n",
    "        exponent = math.exp(-((x - mean)**2)/(2 * stddev**2))\n",
    "        return (1/(math.sqrt(2 * math.pi) * stddev)) * exponent\n",
    "\n",
    "    def predict(self, test_sample):\n",
    "        \"\"\"Predict class for a single sample\"\"\"\n",
    "        max_prob = -1\n",
    "        best_label = None\n",
    "        \n",
    "        for label, stats in self.class_info.items():\n",
    "            prob = self.class_priors[label]\n",
    "            for i, feature_value in enumerate(test_sample):\n",
    "                mean, stddev = stats[i]\n",
    "                prob *= self._gaussian_pdf(feature_value, mean, stddev)\n",
    "            \n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                best_label = label\n",
    "        return best_label\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and prepare data\n",
    "    dataset = load_iris_data(\"iris.csv\")\n",
    "    \n",
    "    # Create label mapping\n",
    "    labels = list(set(row[-1] for row in dataset))\n",
    "    label_map = {label: i for i, label in enumerate(labels)}\n",
    "    reverse_map = {v: k for k, v in label_map.items()}\n",
    "    \n",
    "    # Convert labels to integers\n",
    "    for row in dataset:\n",
    "        row[-1] = label_map[row[-1]]\n",
    "    \n",
    "    # Split into features and labels\n",
    "    X = [row[:-1] for row in dataset]\n",
    "    y = [row[-1] for row in dataset]\n",
    "    \n",
    "    # Create train-test split (80-20)\n",
    "    combined = list(zip(X, y))\n",
    "    random.shuffle(combined)\n",
    "    split = int(0.8 * len(combined))\n",
    "    train_set = combined[:split]\n",
    "    test_set = combined[split:]\n",
    "    \n",
    "    # Prepare training data\n",
    "    X_train = [item[0] for item in train_set]\n",
    "    y_train = [item[1] for item in train_set]\n",
    "    train_data = [x + [y] for x, y in zip(X_train, y_train)]\n",
    "    \n",
    "    # Train model\n",
    "    nb = NaiveBayes()\n",
    "    nb.train(train_data)\n",
    "    \n",
    "    # Test model\n",
    "    correct = wrong = 0\n",
    "    print(\"Test Results:\")\n",
    "    print(\"ID\\tActual\\t\\tPredicted\\tStatus\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for idx, (test_features, actual_label) in enumerate(test_set, 1):\n",
    "        predicted_label = nb.predict(test_features)\n",
    "        status = \"Correct\" if predicted_label == actual_label else \"Wrong\"\n",
    "        \n",
    "        if status == \"Correct\":\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "        \n",
    "        print(f\"{idx}\\t{reverse_map[actual_label]:15}\\t{reverse_map[predicted_label]:15}\\t{status}\")\n",
    "    \n",
    "    print(\"\\nFinal Metrics:\")\n",
    "    print(f\"Correct Predictions: {correct}\")\n",
    "    print(f\"Wrong Predictions: {wrong}\")\n",
    "    print(f\"Accuracy: {100*(correct/(correct+wrong)):.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
